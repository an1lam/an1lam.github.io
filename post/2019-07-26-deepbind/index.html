<!doctype html>
<html lang="en">
<head><meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta content='text/html; charset=utf-8' http-equiv='content-type' />

  <title>Paper Review - DeepBind - Stephen Malina</title>
  <meta content='Paper Review - DeepBind - Stephen Malina' property='title' />
  <meta content='Paper Review - DeepBind - Stephen Malina' property='og:title' />


<meta property="og:description" content="In which I record my thoughts on DeepBind.
What is this paper about? The authors of this paper designed a conv net model to predict how well different proteins will bind to sequences of DNA or RNA. They train one model per protein for many different sequences and show that these models can predict binding affinities for sequences well enough to produce insights regarding the impact of single nucleotide mutations. They then discuss different datasets and areas in which they tested their model and how it performed (often SOTA [as of 2015])." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://an1lam.github.io/post/2019-07-26-deepbind/" />


<meta property="article:published_time" content="2019-07-26T00:00:00&#43;00:00"/>

<meta property="article:modified_time" content="2019-07-26T00:00:00&#43;00:00"/>








<meta name="generator" content="Hugo 0.62.2" />

<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,600" rel="stylesheet">
<style type="text/css">/*https://coolors.co/afd5aa-f0f2ef-a69f98-3d3d3d-8c6057*/
:root {
  --main-color: #8C6056; 
  --secondary-color: #AFD5AA;
  --logo-text-color: #fff;
  --body-text-color: #3d3d3d;
  --heading-text-color: #383838;
  --background-color: #fff;
}</style>
<link href='/css/tachyons.min.css' rel="stylesheet">
<link href='/css/styles.css' rel="stylesheet">


<link rel="icon" 
 
  href='/favicon.ico'

type="image/x-icon"/>


<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>

<link href='/feed.xml' rel="alternate" type="application/atom+xml" title="Stephen Malina" />

</head>
<body class="global-font">
  <nav class=" flex-ns justify-between border-box pa3 pl3-l pr2-l mt1 mt0-ns" id="navbar">
  <div class="flex">
    <a class="f4 fw6 ttu no-underline dim bg-main-color pv1 ph2 br2" id="site-title" href='/' title="Home">Stephen Malina</a>
  </div>
  
  <div class=" flex-ns mt2 mt0-ns pv1">
    
      <a class="link dim dark-gray f6 dib mr2 mr3-l ttu tracked" href='/' title="Home">Home</a>
    
      <a class="link dim dark-gray f6 dib mr2 mr3-l ttu tracked" href='/learning/' title="Learning">Learning</a>
    
      <a class="link dim dark-gray f6 dib mr2 mr3-l ttu tracked" href='/post/' title="Posts">Posts</a>
    
      <a class="link dim dark-gray f6 dib mr2 mr3-l ttu tracked" href='/progress' title="The State of My Mind">The State of My Mind</a>
    
  </div>
  
</nav>
  
<main class="center mv4 content-width ph3">
  <div class="f3 fw6 heading-color heading-font post-title">Paper Review - DeepBind</div>
  <p class="silver f6 mt1 mb4 post-meta">
    <time>26 Jul 2019</time> 
     | 
    
    
    tags: [ <a href='/tags/review' class="link silver">review</a> <a href='/tags/machine-learning' class="link silver">machine-learning</a> <a href='/tags/genomics' class="link silver">genomics</a> <a href='/tags/paper' class="link silver">paper</a> <a href='/tags/notes' class="link silver">notes</a>  ]
    
  </p>
  <div class="lh-copy post-content"><p>In which I record my thoughts on <a href="https://www.nature.com/articles/nbt.3300.pdf">DeepBind</a>.</p>
<h2 id="what-is-this-paper-about">What is this paper about?</h2>
<p>The authors of this paper designed a conv net model to predict how well different proteins will bind to sequences of DNA or RNA. They train one model per protein for many different sequences and show that these models can predict binding affinities for sequences well enough to produce insights regarding the impact of single nucleotide mutations. They then discuss different datasets and areas in which they tested their model and how it performed (often SOTA [as of 2015]).</p>
<h2 id="why-is-this-important">Why is this important?</h2>
<p>At the object level, being able to better predict protein binding affinity to DNA/RNA sequences can help us better understand gene expression and identify mutations that will degrade functioning. At the meta level, this paper (claims to) showcase the power of convolutional neural nets to &ldquo;automatically&rdquo; learn general models of protein binding from heterogeneous inputs. The authors highlight how using a CNN obviates the need for lots of manual hand-tuning, although I suspect, like in many deep learning papers, they're failing to mention other tuning they did to get this model to work as well as it does. The authors point out that, if these sorts of NN models prove useful in bio, future research can essentially ride the curve of deep learning model improvement that they expect to result from the increased investment by industry and academia in deep learning.</p>
<h2 id="technical-methods">Technical Methods</h2>
<p>Their conv net model has 4 layers: a convolutional layer, a rectification layer, a max/avg pooling layer, and one or two neuron layers depending on whic performs better on the validation set.</p>
<p>Each model is trained to determine the binding affinity (or binding confidence in the classification case) for one protein. Their models take a DNA or RNA sequence as input and output a real-valued binding affinity score that represents the likelihood of that protein binding to this sequence (note: I still don't understand what exactly this score represents). Specifically, they convert a sequence of $ m $ characters chosen from {A, C, T, G} (in the case of DNA) into a padding $m \times 4$-length vector where each row's values sum to 1 and a $1$ at position $j,k$ indicates the existence of nucleotide $k$ at position $j$.</p>
<p>During training, they use dropout on both NN layers (when applicable) and use random search to find good hyperparameters. Since their models actually can function as classifiers or predictors, they use different loss functions to train each &ndash; negative log likelihood for classification and MSE for prediction.</p>
<h2 id="criticisms">Criticisms</h2>
<h3 id="to-hide-or-not-to-hide">To Hide Or Not To Hide</h3>
<p>I'm not sure how common this is, but the decision to selectively use the hidden ReLu layer depending on validation performance felt unmotivated to me. I'd be interested in learning more about the intuition behind why removing it sometimes improves performance.</p>
<h3 id="never-roll-your-ownhttpsnewsycombinatorcomitemid19947317-models"><a href="https://news.ycombinator.com/item?id=19947317">Never Roll Your Own&hellip;</a> Models</h3>
<p>Their model is &ldquo;built from the ground up in C++ and Python, with only low-level dependencies (CUDA and Numpy).&rdquo; In fairness, this paper was written in 2015, so the Tensorflow paper had either just dropped or not even appeared yet. Unlike some <a href="https://twitter.com/kchonyc/status/1149826779999363072">reviewers</a>, I don't expect the authors of papers to time travel, so maybe this just shows how fast things progress in ML these days that I now expect a paper like this to use off-the-shelf components.</p>
<p>Regardless, someone has since created a <a href="https://github.com/kundajelab/DeepBindToKeras/blob/master/DeepBind%20to%20Keras.ipynb">Keras version</a> of DeepBind.</p>
<h2 id="speculative-future-extensions">Speculative Future Extensions</h2>
<ul>
<li>Using one big model to learn all the different protein affinities. I'm not exactly sure how you'd do this, but you'd have to have some way of parameterizing your model with both the protein and sequence as input. In the ideal case, your model would perform better due to learning relationships between proteins in addition to motif-to-affinity relationships.</li>
<li>Leverage something better than random parameter search (bayesian optimization, one of the newfangled evolutionary strategies, etc.) to see if you can get better performance without compromising generalization. I suspect this would be more important if you wanted to train one model on multiple (or all) of the proteins as I mentioned in the prior bullet.</li>
</ul>
<h2 id="questions">Questions</h2>
<ul>
<li>What does the outputted score actually represent when it's a continuous value? I get that it's modeling the protein's binding affinity but what's the unit of measure for the thing being predicted? This is one of those embarrassing &ldquo;I don't know anything about bio&rdquo; questions&hellip;</li>
<li>What's the physics/chemistry intuition behind using motif-based convolutions? Is it purely structural, i.e. is the assumption that the nucleotide sequence determines its structure and its structure determines whether the protein will bind to it?</li>
</ul>
</div>
</main>
 






<div class="tl fixed list-pages lh-copy" id="contents-list"></div>



<div class="pagination tc tr-l db fixed-l bottom-2-l right-2-l mb3 mb0-l">
  
<a id="scroll-to-top" class="f6 o-0 link br2 ph2 pv1 mb1 bg-main-color pointer" onclick="topFunction()" style="color: #fff; visibility: hidden; display: none; transition: opacity .5s, visibility .5s;" title="back to top">back to top</a>
<br>
  <p class="mb0 mt2">
  <a href="https://an1lam.github.io/post/2019-05-18-thoughts-on-stoicism/">prev post</a>
  <a href="https://an1lam.github.io/post/2019-08-05-basset/">next post</a>
  </p>
</div>

  <footer class="content-width mt0 mt5-l mb4 f6 center ph3 gray tc tl-l">
  <hr class="dn db-l ml0-l gray w3"><br>
  Powered by <a href="https://gohugo.io/" target="_blank" class="link gray dim">Hugo</a>, based on the <a href="https://github.com/lingxz/er" target="_blank" class="link gray dim">Er</a> theme. <br>
  
</footer>
  



<script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.min.js"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.css">
<style>.is-active-link::before { background-color: var(--secondary-color); }</style>




<script type="text/javascript">
var prevScrollpos = window.pageYOffset;
window.onscroll = function() {
  var currentScrollPos = window.pageYOffset;

  
  if (document.getElementById("tag-cloud") !== null) { 
    if (prevScrollpos > currentScrollPos) { 
      document.getElementById("tag-cloud").style.visibility = "visible";
      document.getElementById("tag-cloud").style.opacity = "1";
    } else {
      document.getElementById("tag-cloud").style.visibility = "hidden";
      document.getElementById("tag-cloud").style.opacity = "0";
    }
  }
  

  
  if (document.body.scrollTop > 1000 || document.documentElement.scrollTop > 1000) {
      document.getElementById("scroll-to-top").style.display = "inline";
      document.getElementById("scroll-to-top").style.visibility = "visible";
      document.getElementById("scroll-to-top").style.opacity = "1";
  } else {
      document.getElementById("scroll-to-top").style.visibility = "hidden";
      document.getElementById("scroll-to-top").style.opacity = "0";
  }
  
  prevScrollpos = currentScrollPos;
}


function topFunction() {
  document.body.scrollTop = 0; 
  document.documentElement.scrollTop = 0; 
}






if (document.getElementById("contents-list") !== null && document.getElementsByClassName("post-content").length !== 0) { 
  tocbot.init({
    
    tocSelector: '#contents-list',
    
    contentSelector: '.post-content',
    
    headingSelector: 'h1, h2, h3',
  });
}


</script>




<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/contrib/auto-render.min.js" integrity="sha384-dq1/gEHSxPZQ7DdrM82ID4YVol9BYyU7GbWlIwnwyPzotpoc57wDw/guX8EaYGPx" crossorigin="anonymous"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.css">
<script>
  renderMathInElement(document.body,
    {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "$", right: "$", display: false},
        ]
    }
  );

  var inlineMathArray = document.querySelectorAll("script[type='math/tex']");
  for (var i = 0; i < inlineMathArray.length; i++) {
    var inlineMath = inlineMathArray[i];
    var tex = inlineMath.innerText || inlineMath.textContent;
    var replaced = document.createElement("span");
    replaced.innerHTML = katex.renderToString(tex, {displayMode: false});
    inlineMath.parentNode.replaceChild(replaced, inlineMath);
  }

  var displayMathArray = document.querySelectorAll("script[type='math/tex; mode=display']");
  for (var i = 0; i < displayMathArray.length; i++) {
    var displayMath = displayMathArray[i];
    var tex = displayMath.innerHTML;
    var replaced = document.createElement("span");
    replaced.innerHTML = katex.renderToString(tex.replace(/%.*/g, ''), {displayMode: true});
    displayMath.parentNode.replaceChild(replaced, displayMath);
  }
</script>


</body>
</html>