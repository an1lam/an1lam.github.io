<!DOCTYPE html>
<html lang="en-us"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
<title>AI Omens: 2&#43; Years Later - Stephen Malina</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
<meta name="description"
    content="In September 2022, I wrote a post describing a set of &ldquo;omens&rdquo; that, if observed, would indicate faster-than-expected AI progress. I framed many of these in the context of 0-5 years, but obviously AI moves too fast to wait until 2027 to review these. Consider this post an arbitrarily timed intermediate check in nominally triggered by my friend Leo writing an interesting and provocative series.
The rest of this post assumes you&rsquo;ve skimmed the omens post, so if you haven&rsquo;t already, I recommend doing that now. ">
<link rel="canonical" href="http://localhost:1313/post/2025-05-31-reflecting-on-ai-omens/" />



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/modern-normalize/1.1.0/modern-normalize.min.css" crossorigin="anonymous" referrerpolicy="no-referrer" />



<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
<link rel="preload" as="style"
      href="https://fonts.googleapis.com/css?family=Noto+Serif+SC|Noto+Emoji&display=swap" />
<link rel="stylesheet"
      href="https://fonts.googleapis.com/css?family=Noto+Serif+SC|Noto+Emoji&display=swap"
      media="print" onload="this.media='all'" />
<noscript>
<link rel="stylesheet"
      href="https://fonts.googleapis.com/css?family=Noto+Serif+SC&display=swap" />
</noscript>


  
  
    
      <link rel="stylesheet" href="http://localhost:1313/css/hugo-tufte.min.css">
    
  



  
  
    
      <link rel="stylesheet" href="http://localhost:1313/css/hugo-tufte-options.min.css">
    
  


<link rel="stylesheet" href="http://localhost:1313/css/hugo-tufte-override.css">

</head>
<body>


<article id="main">
  <section>
<h1 class="content-title">AI Omens: 2&#43; Years Later&nbsp;:: Draft</h1></section>

  

  <section><p>In September 2022, I wrote a <a href="https://stephenmalina.com/post/2022-09-17-ai-omens/">post</a> describing a set of &ldquo;omens&rdquo; that, if observed, would indicate faster-than-expected AI progress. I framed many of these in the context of 0-5 years, but obviously AI moves too fast to wait until 2027 to review these. Consider this post an arbitrarily timed intermediate check in nominally triggered by my friend Leo writing an interesting and provocative <a href="https://situational-awareness.ai/">series</a>.</p>
<p><em>The rest of this post assumes you&rsquo;ve skimmed the omens post, so if you haven&rsquo;t already, I recommend doing that now.</em></p>
<h1 id="overall-takeaways-and-learnings">
Overall takeaways and learnings
<a href="#overall-takeaways-and-learnings" class="heading-anchor">#</a>
</h1>
<p><strong>Pure software moves faster</strong></p>
<p><strong>Research-wise a lot rides on the “unhobbling” thesis</strong></p>
<ul>
<li>Leo describes improvements as unhobblings. If that&rsquo;s the right framing then some of the problems that haven&rsquo;t been solved are more like buffs than bottlenecks</li>
<li>If they&rsquo;re instead bottlenecks,</li>
</ul>
<h1 id="section-by-section-review">
Section-by-section review
<a href="#section-by-section-review" class="heading-anchor">#</a>
</h1>
<p>1. Progress on/towards pure software omens is impressive<br>
1. $1B ARR product already crossed<br>
2. 1M active users easily achieved<br>
2. Intellectual feats section is interesting<br>
1. Basically none achieved yet. Exception is complex prediction, although even there I&rsquo;m not sure if AF3 could handle AAV. Ironically learning from scientific papers feels more tractable, but I rated this as very low probability<br>
2. But progress on benchmarks like GPQA feels very impressive<br>
3. Left out medical tasks but that seems like an area of rapid progress<br>
3. Progress towards open-ended and longer time horizon reasoning plus continual learning<br>
1. Long contexts is happening crazy fast. Book length discussion is basically here<br>
2. Software is again the area of most rapid progress: AI designs entire engineering systems, either software or physical based on design documents &amp; Q&amp;A with humans.<br>
3. ~no progress on continual learning, but hard to tell with labs closing off. Also may just not have the eye of sauron right now.<br>
1. There still aren&rsquo;t _that_ many good AI researchers in the world<br>
# Takeaways<br>
1. I&rsquo;ve snapshotted the original piece [here](). I intend to update it substantially in the next few months.<br>
2. I wish I&rsquo;d done fewer omens and included more reasoning. It&rsquo;s surprisingly hard to remember what I thought at the time and updating on just correctness is hard. Implication: RLHF is hard for humans :)<br>
3. Robotics feels underrated by these omens. By the five year mark I suspect a lot of them will be hit<br>
1. Examples: progress with humanoids (Figure, Unitree)<br>
2. RT series of models</p>
<h2 id="omen-by-omen-review">
Omen-by-omen review
<a href="#omen-by-omen-review" class="heading-anchor">#</a>
</h2>
<h3 id="rapid-economic-growth">
Rapid economic growth
<a href="#rapid-economic-growth" class="heading-anchor">#</a>
</h3>
<p>&gt; - Self-driving car deployment continues apace and even accelerates, starting to replace a meaningful (10%) fraction of the ride share market.</p>
<p>For the purpose of evaluating this one, I’m just going to focus on Uber to simplify things. But I recognize that to grade it properly, I’d need to look at global rideshare mileage compared to global self-driving deployment.</p>
<p>One month ago, Waymo <a href="https://twitter.com/Waymo/status/1788693361047515522?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1788693361047515522%7Ctwgr%5E3ca3c18658cd7c38d0e8d63a7d0078b3b9447567%7Ctwcon%5Es1_c10&amp;ref_url=https%3A%2F%2Fwww.redditmedia.com%2Fmediaembed%2F1co9loz%2F%3Fresponsive%3Dtrueis_nightmode%3Dfalse">announced</a> that they’re making 50,000 trips per week across three cities. In 2023, Uber logged an average of 26 million trips per day (<a href="https://www.businessofapps.com/data/uber-statistics/">source</a>), so 500x more than Waymo. That means in order for Waymo alone to get to 10% of Uber’s trip volume, it would need to 50x in the next 3.5 years. Revenue tells a similar, although slightly more optimistic story. It’s hard to find exact numbers but my best guess is that Waymo earned around $1B in revenue this past year compared to Uber’s $37B, meaning they’d need to 3.7x their revenue to reach 10% of Uber’s (current).</p>
<p>Now, astute readers will notice there’s a big gap here between trip volume multiples and revenue. I don’t know how to explain this and it makes me think one of my numbers is off by an order of magnitude… The former estimate makes the omen seem unlikely to come to pass in the next 3.5 years, whereas the latter makes it seem quite possible. This makes evaluating plausibility hard, so I’m going to cheat and just trust the estimated number of trips over revenue.</p>
<p>Evaluating plausibility based on that, Waymo catching up to Uber by September 2027 seems possible but not unlikely to me given how their rollout has proceeded to date. Just expanding to the top 10-20 major cities in the US presumably gets them around 5x growth, but regulatory tailwinds combined with their extremely careful approach make me think they’re more likely to continue at an only slightly. For example, in 2024, they’re <a href="https://waymo.com/blog/2024/03/scaling-waymo-one-safely-across-four-cities-this-year/">seemingly</a> only expanding to Austin and the rest of LA.</p>
<p>I’m not factoring in other rideshare platforms here, since Waymo seems to be far and away the furthest ahead, but Tesla is a different story. In 2023, Tesla produced and delivered <a href="https://ir.tesla.com/press-release/tesla-vehicle-production-deliveries-and-date-financial-results-webcast-fourth-quarter-2023">almost 2M vehicles</a>, and a month and a half ago, Tesla FSD <a href="https://driveteslacanada.ca/news/tesla-fsd-hits-1-billion-miles-driven/">hit 1B miles driven</a>. As part of that, Tesla claimed half a billion dollars in revenue from FSD 2023. Uber’s revenue in 2023 was $37B, so what really matters for the purposes of the omen is growth. and at least today, growth of FSD sales <a href="https://www.bloomberg.com/news/articles/2024-04-24/tesla-tsla-keeps-unlocking-less-fsd-software-revenue-than-hoped">seems to be slowing down</a>.</p>
<p>That said, I’m definitely not counting Tesla out here. At current subscription costs of $100/month, Tesla would need ~3M subscribers to hit 10% Uber’s current revenue. According to this <a href="https://www.reddit.com/r/TeslaModelY/comments/1btagvf/comment/kxod74l/">reddit thread</a>, there are around 2M Teslas on the road today, so even if FSD rolled out to every single Tesla on the road, there’d still be a 1.5x gap to close with Uber’s current revenue. And realistically, not every Tesla owner will pay for FSD. On the other hand, I will never fully count out Elon and if Tesla can reignite growth even a bit beyond Uber’s, hitting 10% of the market in terms of revenue (and mileage) before 2027 seems quite possible.</p>
<p>Stepping back, the main takeaway for me here is that it’s important to factor in sociological and regulatory factors when thinking about these omens. Looking at the data and news, self-driving deployment continues to be more rate limited by sociological factors such as people being inherently wary of self-driving cars and getting extremely upset when they do things like block roads than actual safety. In terms of actual safety, I’m reasonably confident that both <a href="https://www.tesla.com/blog/bigger-picture-autopilot-safety">Tesla</a> and <a href="https://waymo.com/blog/2023/12/waymo-significantly-outperforms-comparable-human-benchmarks-over-7-million/#:~:text=When%20considering%20all%20locations%20together,2.78%20for%20the%20human%20benchmark)">Waymo</a> are close to, if not already a ways past median human safety, and I expect that gap to widen substantially before 2027.</p>
<p>&gt; - At least one LLM-driven product such as <a href="https://github.com/features/copilot">Copilot</a> has 1 million unique active users. One benchmark here is Figma, which according to <a href="https://techcrunch.com/2022/06/08/figmas-dylan-field-will-discuss-evolving-as-a-leader-and-why-fun-is-an-essential-company-value-at-techcrunch-disrupt/#:~:text=Roughly%204%20million%20people%20use,%2C%20Slack%2C%20Twitter%20and%20Volvo">this article</a> from June, 2022, has 4 million unique users, There’s also a subtlety here that’s a little hard to deal with, which is that AI tools like DALL-E 2 get a ton of sign-ups but then experience rapid user drop-off. I’m just going to have to use my judgment here since I’m looking for widespread <em>and persistent</em> usage. I’d buy even faster acceleration if white collar <a href="http://adept.ai">AI tools</a> routinely start getting used to make spreadsheets, powerpoints, etc. for businesses, but I suspect this is unlikely even in a relatively short timelines world due to structural factors.</p>
<p>In contrast to the self-driving car one, I obviously undershot here. Around 6 months ago, Sam Altman said that ChatGPT <a href="https://www.linkedin.com/news/story/chatgpt-hits-100m-weekly-users-5808204/">had 100 million weekly active users</a>. There are claims that usage is leveling off, but I haven’t seen any claims that it&rsquo;s declining. That alone would mean this omen has already come to pass, but ChatGPT is by no means the only product to have crossed this threshold. Github Copilot had 1.3 million paying customers <a href="https://visualstudiomagazine.com/Articles/2024/02/05/copilot-numbers.aspx">as of February</a>, Perplexity <a href="https://techeconomy.ng/perplexity-ai-secures-70-million-funding-round-valued-at-520-million/">allegedly</a> has 10 million monthly active users with rapid growth, and Gemini <a href="https://www.perplexity.ai/search/how-many-daus-.yySUbQ0SMibpzV6dx5I2g#0">either has already crossed or soon will cross</a> the 1 million active users threshold.</p>
<p>And while acceleration may be slightly slower on the enterprise front, it’s still rapid relative to the expectation I set. Anecdotally, many of my friends and acquaintances use at least some enterprise features of Copilot of ChatGPT and I expect that number to increase as the “enterprise context problem” gets solved.</p>
<p>So consumer and enterprise adoption of AI tools has triggered my omen. Personally, I expect this growth to continue, but even if the adoption curve were to plateau as <a href="https://www.wsj.com/tech/ai/the-ai-revolution-is-already-losing-steam-a93478b1">some are claiming</a>, we’d already be well beyond the level of adoption I originally stated would constitute an omen of acceleration.</p>
<p>As will become a theme, the main takeaway here seems to be that pure software adoption has far fewer barriers to explosion than anything that interacts with the physical world and/or regulation.</p>
<p>- AI manufacturing tools from companies like <a href="https://covariant.ai/">Covariant</a> start achieving real market penetration.</p>
<p>Hard for me to grade this one. Investment in robotics is clearly skyrocketing, with multiple well-funded humanoid robotics companies (<a href="http://figure.ai">Figure</a>, <a href="http://1x.tech">1X</a>, <a href="https://www.forbes.com/sites/kenrickcai/2024/05/13/kyle-vogt-the-bot-company-startup-funding/?sh=1d87c0765402">Kyle Vogt and co’s stealth company</a>) entering the scene as well as <a href="https://physicalintelligence.company/">competitors</a> to Covariant. Yet, as far as I know, “real market penetration” has not yet been achieved. Despite that, I’d say I’m more optimistic about this one than I was at the time of writing. Scaling <a href="https://www.interconnects.ai/p/robotic-foundation-models">clearly works</a> for robotics, so the outstanding Qs for me are:</p>
<ol>
<li>How hard is it to go from 1 to 5 or however many 9s you need to replace a human?</li>
<li>How much does (<em>waves hands around</em>) “physical world messiness” slow down rapid deployment?</li>
<li>Does China leapfrog here because their manufacturing base is more dynamic and further along on the, mostly AI free, automation adoption curve?</li>
</ol>
<p>- Radiologists and pathologists at least become more productive as a result of AI tooling. I [controversially](<a href="https://twitter.com/random">https://twitter.com/random</a>_walker/status/1562070877860012032?s=20&amp;t=wAzkxzkxwq8AHAnCI7NeKw) do think they could probably be replaced in the medium term if not the short but I highly highly doubt they will be for regulatory capture + extreme precautionary principle reasons.</p>
<p>Depending on who I ask, radiology and pathology AI tools are “basically there” or “still making obvious mistakes”. From a cursory look at <a href="https://www.radpartners.com/2023/11/radiology-partners-deploys-clinical-ai-across-more-than-20-million-annual-patient-exams/">various</a> reports and stats, I came away feeling like adoption is growing, but true replacement or otherwise disruptive usage isn’t really happening. This is based on the fact that supposedly around 30% of radiologists use some sort of AI tool in their work, but most seem to be doing so in a cursory way. On top of that, the number of radiologists practicing is, if anything, <a href="https://medicushcs.com/resources/navigating-the-radiologist-shortage">growing too slowly to meet demand</a>.</p>
<p>On the flip side, research progress feels rapid, with multimodal models like <a href="https://research.google/blog/advancing-medical-ai-with-med-gemini/">Med-Gemini</a> continuing to make Pareto improvements on medical tasks, including radiology and pathology related evals. But to be truly transformative, these tools need to be integrated into actual clinical practice, which itself will involve multi-year software projects.</p>
<p>Together, this reinforces my takeaway that interaction with the physical world, legacy systems, and regulatory barriers all create overhangs that slow the translation of sufficient capabilities to real world disruptive deployment.</p>
<p>- AI systems start seeing slow but real adoption in food industry tasks like <a href="https://misorobotics.com/flippy-2/">making burgers</a> and [taking orders](<a href="https://emerj.com/ai-sector-overviews/artificial-intelligence-at-mcdonalds/)">https://emerj.com/ai-sector-overviews/artificial-intelligence-at-mcdonalds/)</a>. Or for another example, automated coffee machines like [Cafe X](<a href="https://thespoon.tech/cafe-x-re-opens-sfo-robot-barista/">https://thespoon.tech/cafe-x-re-opens-sfo-robot-barista/</a>) (which I recently used on a layover in SF) spread to more airports or similar settings.</p>
<p>I framed this as focused on last mile tasks such as cooking and serving. My sense is not much has changed here since I wrote this, although the investment in humanoid robotics presumably is partly targeted at these types of tasks.</p>
<p>One thing I underrated at the time was innovation upstream in the supply chain. Although it’s not as sexy as LLMs and AGI, it seems like more prosaic ML systems are slowly but surely making their way into multiple stages of the food supply chain. Be it more accurate nowcasting, <a href="https://www.techopedia.com/precision-farming-how-ai-and-drones-are-reshaping-agriculture">drones for data collection</a>, or <a href="https://www.chicagotribune.com/2024/04/01/caterpillar-peoria-proving-ground-autonomous-tractors/#:~:text=Caterpillar%2C%20which%20began%20experimenting%20with,the%20early%20stages%20of%20commercialization.">automated tractors</a>, my sense is that ML is a key piece in ensuring food production continues to become more efficient.</p>
<p>My main takeaway here is that it’s a bit early for the last mile food production sorts of tasks and I’d be even more surprised if we see substantial replacement by 2027 even with rapid research progress. A secondary takeaway is that for specialty areas like this, it’s hard for me to even evaluate omens unless they’re framed more specifically or the progress is extremely obvious even to a casual observer.</p>
<p>- LLM companies’ products achieving promising uptake.</p>
<p>See above, clearly happening.</p>
<p>- Signs that robotics systems that help humans are on the cusp of being useful. E.g., Google or [Everyday Robotics](<a href="https://everydayrobots.com/">https://everydayrobots.com/</a>) demonstrates an AI janitor that actually operates autonomously in their or another office.</p>
<p>Mostly covered above, this isn’t happening yet, although the Kyle Vogt and co. stealth startup I mentioned is allegedly working on home robotics. Because the home is such a difficult setting, I continue to think this is even more unlikely in the 5 year time horizon than widespread deployment in manufacturing or other industrial settings by 2027. If I’m using a home robot besides a vacuum or another bespoke device by that date, I’ll be super surprised.</p>
<h3 id="demonstrations-of-formidable-intelligence">
Demonstrations of formidable intelligence
<a href="#demonstrations-of-formidable-intelligence" class="heading-anchor">#</a>
</h3>
<ul>
<li><a href="https://manifold.markets/Austin/will-an-ai-get-gold-on-any-internat">AI wins a medal in the IMO by (end of) 2025</a></li>
</ul>
<p>Seems plausible but unlikely (35% chance). Adding a year and 9 months shifts the likelihood a lot for me though. I’d say 65% chance by September 2027. Again, stepping back, I think math is going to be an area where we’ll get other omens of acceleration that I didn’t predict, for a few reasons:</p>
<ol>
<li>It lacks any of the physical world barriers of other sciences like biology.</li>
<li>Synthetic data generation is much easier using things like proof assistants.</li>
<li>We’ve seen <a href="https://bounded-regret.ghost.io/scoring-ml-forecasts-for-2023/">crazy rapid progress</a> on math benchmarks over the past few years.</li>
</ol>
<ul>
<li>AI proves an important, broad theorem that humans have been unable to prove up until now
<ul>
<li>Examples: Riemann Hypothesis</li>
</ul>
</li>
</ul>
<p>I think this is more likely thanI thought it was at the time of writing. While AI doing the entire proof end-to-end seems a bit less likely, I am overall more sympathetic to Christian’s perspective <a href="https://x.com/ChrSzegedy/status/1598341927828594688">here</a> than Francois’s.</p>
<ul>
<li>AI programming model outperforms best competitive programmers (Manifold questions: <a href="https://manifold.markets/PeterHro%C5%A1%C5%A1o/will-ai-outcompete-best-humans-in-c-c91105439712">1</a>).</li>
</ul>
<p>Yep, this may sound crazy, but I think this is a 60% chance at least by September 2027. As I’m going through these, I’m realizing I probably need to separately write up my views on AI progress for programming and math over the next few years but my reasons are similar to math but amplified by economic incentives.</p>
<p>First of all, programming benchmarks are rapidly falling. Over the course of two years, AlphaCode 2 <a href="https://techcrunch.com/2023/12/06/deepmind-unveils-alphacode-2-powered-by-gemini/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAACbZPWWk0HGE1H-l33RVZp50AUXkCg-e860cbAEgaDIEPD4vROMyT99dvBSiqW6bTR_TxcPskgNQQQMNQqfhLGr1pSztQgdFcUx42K4x3i16yvKGzqCMxEHTsCCu1FeEyCAOCLgVslk5csvqX2Ac-FdJMiWIe4lOWq7oqGlKL-H8">improved by almost 2x</a> over AlphaCode and we see similar trends across other code benchmarks such as <a href="https://paperswithcode.com/sota/code-generation-on-humaneval">HumanEval</a>.</p>
<ul>
<li>AI programmers start replacing junior programmers in industry. Example: Can I use an AI system to take a first pass at designing a web app that I’ve described in text/maybe mock-ups?</li>
</ul>
<p>I’m 50/50 here.</p>
<p>I am bullish on capabilities continuing to grow and am confident code will be the place we first see successful deployment of agents (see <a href="http://devin.ai">Devin</a>, <a href="http://lindy.ai">Lindy</a>, <a href="https://aider.chat/">Aider</a>, <a href="http://Swe-agent.com">SWE-Agent</a>). For example, I think designing a simple web app from text/mock-ups is already close to doable if you’re willing to do some touch up after the fact.</p>
<p>That said, I’ve also come to see how replacement is more complicated than just looking at individual capabilities. Replacing someone requires either reorganizing surrounding systems and processes or replacing the entire bundle of tasks they do. In the case of a software engineer, this means you don’t just need to replace writing code, but also debugging issues that come up, responding to users you support, metarational bridging between requirements and implementation, and much more.</p>
<p>On the flip side, I do think we’re already seeing incremental shifts towards, especially smaller companie,s hiring fewer junior engineers, but it&rsquo;s hard to tell if that has much to do with AI or just the end of ZIRP.</p>
<ul>
<li>AI programming system can automatically and reliably perform large scale refactorings. Examples include migrating a codebase from one framework to another, “remove huggingface from this modeling script and replace it with pytorch”, and other similar tasks.</li>
</ul>
<p>I have been surprised how little research and evals has focused on this. It seems like an especially tractable task because you can lean heavily on golden master style tests to confirm correctness.</p>
<ul>
<li><a href="https://elicit.org/">AI research assistants</a> helpful enough for analyzing papers that I actually trust their responses to questions vs. just using them as glorified search.</li>
<li>AI systems beat humans at forecasting medium to long term events.</li>
<li>AI engineering systems design new materials or artifacts that unblock a key bottleneck in some engineering process. Examples:
<ul>
<li>Nanosystem that has a previous unseen capability designed primarily by an AI system.</li>
<li>New material better than a material that’s had a lot of human effort put into improving it such as carbon fiber and is actually usable.</li>
</ul>
</li>
<li>Models continue to knock down biological prediction tasks. Examples:
<ul>
<li>Protein complex structure prediction for large protein assemblies vs. <a href="https://www.biorxiv.org/content/10.1101/2021.10.04.463034v2">small sets</a> <a href="https://www.biorxiv.org/content/10.1101/2022.09.09.507333v1">of monomers</a>. As a close to home example, if a model could predict the entire structure of the AAV capsid, that would be very impressive.</li>
<li>In a similar vein, if structure models become able to predict variant effects accurately, that would constitute greater than expected progress.</li>
<li>Accurately predicting time series dynamics vs. static structures.</li>
<li>Improved receptor binding prediction, with bonus points for if it’s clearly getting used to design drugs more quickly/effectively.</li>
</ul>
</li>
</ul>
<p>Interestingly, I’d say I was relatively calibrated here. While AlphaFold 3 is quite impressive, I highly doubt it can predict the full AAV complex structure with its 60 sub-units. I do think we&rsquo;re seeing and are going to see substantial improvements in receptor binding prediction (see DiffDock-L), but it&rsquo;s a little early to declare victory here.</p>
<ul>
<li>Various forms of progress towards the world described in <a href="https://markov.bio/biomedical-progress/">A Future History of Biomedical Progress</a> in the next 5 years. Examples:
<ul>
<li>Models that learn from scientific papers and writing actually doing something useful. (I will put myself out there for this one and say that I think this is very (&lt;10%) unlikely.</li>
<li>Models drive automated robotic laboratories that both run experiments and automatically decide which experiments to perform next.</li>
</ul>
</li>
</ul>
<p>I&rsquo;ve become more optimistic about models that learn from the literature and design experiments. Work like WikiCrow shows that models can understand literature better than I expected, and vision model improvements are a big unlock for, especially biology related, literature understanding. On the experimental design front, I think with enough schlep, this could even be possible today for proof-of-concept experiments such as say optimizing GFP.</p>
<p>I&rsquo;m less sure about how fast the truly closed loop automated lab stuff will be because it already depends a lot on the application. For applications where everything can be done on a plate (<em>in vitro</em> only), some companies are already doing this using “traditional” active learning. On the other hand, it&rsquo;s by no means widespread and</p>
</section>
  <section><footer class="page-footer">
<hr />

<div class="previous-post" style="display:inline-block;">
  
  <a class="link-reverse" href="http://localhost:1313/post/2022-09-17-ai-omens/?ref=footer">« AI Omens: Signs of AI acceleration</a>
  
</div>

<div class="next-post", style="display:inline-block;float:right;">
  
  <a class="link-reverse" href="http://localhost:1313/post/2022-11-16-gpt4-predictions/?ref=footer">GPT4 Predictions »</a>
  
</div>

<ul class="page-footer-menu">
  
  
  <li><a href="https://twitter.com/an1lam">Twitter</a></li>
  
  
  

  
  <li><a href="https://github.com/an1lam">GitHub</a></li>
  

  

  

  

  

  

  

  

  

  

  
  <li><a href="https://scholar.google.com/citations?user=Q6_3PJEAAAAJ">Google Scholar</a></li>
  
  
  
    <li><a href="https://github.com/an1lam"><i class='fa fa-github fa-2x'></i>  </a></li>
  
    <li><a href="https://twitter.com/an1lam"><i class='fa fa-twitter fa-2x'></i>  </a></li>
  
    <li><a href="mailto:stephenmalina@gmail.com"><i class='fa fa-envelope fa-2x'></i>  </a></li>
  
    <li><a href="https://stackoverflow.com/users/1631855/an1lam"><i class='fa fa-stack-overflow fa-2x'></i>  </a></li>
  
</ul>


<p>
  Powered by <a href="https://gohugo.io">Hugo</a> and the
  <a href="https://github.com/loikein/hugo-tufte">Tufte theme</a>.
</p>




</footer>
</section>
  <section><nav class="menu">
    <ul>
    
        <li><a href="http://localhost:1313/">Home</a></li>
    
        <li><a href="http://localhost:1313/about">About</a></li>
    
        <li><a href="http://localhost:1313/post">Post</a></li>
    
        <li><a href="http://localhost:1313/bets">Bets</a></li>
    
        <li><a href="http://localhost:1313/greatest-hits">Greatest Hits</a></li>
    
        <li><a href="http://localhost:1313/tags">Tags</a></li>
    
    </ul>
</nav>
</section>
</article>





</body>

</html>
