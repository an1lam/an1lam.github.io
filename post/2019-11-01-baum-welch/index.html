<!DOCTYPE html>
<html lang="en-us"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=57852&amp;path=livereload" data-no-instant defer></script>
<title>Let&#39;s Derive - Baum-Welch for HMMs - Stephen Malina</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
<meta name="description"
    content="I&rsquo;ve gotten so tired of reading other people&rsquo;s descriptions of Baum Welch that don&rsquo;t seem to help me understand it better so I&rsquo;ve decided to write my own. Hopefully, this makes it so that I never have to read anyone else&rsquo;s description again.

Reader Assumptions
#

Since I&rsquo;m writing this for myself, I&rsquo;m going to assume a lot of knowledge. If you&rsquo;ve never heard of an HMM, this post&rsquo;s probably not for you. ">
<link rel="canonical" href="http://localhost:57852/post/2019-11-01-baum-welch/" />



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/modern-normalize/1.1.0/modern-normalize.min.css" crossorigin="anonymous" referrerpolicy="no-referrer" />



<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
<link rel="preload" as="style"
      href="https://fonts.googleapis.com/css?family=Noto+Serif+SC|Noto+Emoji&display=swap" />
<link rel="stylesheet"
      href="https://fonts.googleapis.com/css?family=Noto+Serif+SC|Noto+Emoji&display=swap"
      media="print" onload="this.media='all'" />
<noscript>
<link rel="stylesheet"
      href="https://fonts.googleapis.com/css?family=Noto+Serif+SC&display=swap" />
</noscript>


  
  
    
      <link rel="stylesheet" href="/css/hugo-tufte.min.css">
    
  



  
  
    
      <link rel="stylesheet" href="/css/hugo-tufte-options.min.css">
    
  


<link rel="stylesheet" href="/css/hugo-tufte-override.css">

</head>
<body>


<article id="main">
  <section>
<h1 class="content-title">Let&#39;s Derive - Baum-Welch for HMMs&nbsp;:: Draft</h1></section>

  

  <section><p>I&rsquo;ve gotten so tired of reading other people&rsquo;s descriptions of Baum Welch that don&rsquo;t seem to help me understand it better so I&rsquo;ve decided to write my own. Hopefully, this makes it so that I never have to read anyone else&rsquo;s description again.</p>
<h1 id="reader-assumptions">
Reader Assumptions
<a href="#reader-assumptions" class="heading-anchor">#</a>
</h1>
<p>Since I&rsquo;m writing this for myself, I&rsquo;m going to assume a lot of knowledge. If you&rsquo;ve never heard of an HMM, this post&rsquo;s probably not for you.</p>
<h1 id="notation">
Notation
<a href="#notation" class="heading-anchor">#</a>
</h1>
<p>As is clearly superior to any other choice of names (in my unbiased opinion), our HMM will be described by \( \{ S, O, T, E, v \} \) where:</p>
<ul>
<li>\( S \) is a set of possible discrete states with length \( K \);</li>
<li>\( O \) is a set of possible emissions with length \( L \);</li>
<li>\( T \) is our transition matrix, indexed by two states, typically denoted \( k \in [K] \) and \( l \in [K] \);</li>
<li>\( E \) is our emission matrix, indexed by a state \( k \in [K] \) and an emission \( o \in [O] \); and</li>
<li>\( v \) is our set of initial possible states (length 1 in the example we discuss).</li>
</ul>
<p>\( T \) and \( E \) have the following probabilistic interpretations. \( T_{kl} \) denotes the probability of a transition from state \( k \) to state \( l \). In other words, if we somehow observe that an HMM was in state \( \pi_{t} = k \) at time step \( t \) where \( 1 \leq t &lt; T \), then
\[ P(\pi_t = l \mid \pi_t = k) = T_{kl}. \]</p>
<p>\( E_{ko} \) denotes the probability of emission \( o \) from our HMM in state \( k \). In other words, if we&rsquo;re given the hidden state of our HMM, \( \pi_t = k \) at time step \( 1 \leq t &lt; T \) and want to estimate the probability of emission \( t \), \( x_t \), taking on different values, then
\[
\begin{align}
&amp; P(x_t = o \mid \pi_t = k) = E_{ko} &amp; \text{(for all \(o \in O\))}.
\end{align}
\]</p>
<p>Finally, as will become relevant shortly, we&rsquo;ll call our dataset \( X \) (with lower-case \( x \) denoting a single sample) and vectors of latent variables/unknown states \( \pi \).</p>
<h1 id="problem-statement">
Problem Statement
<a href="#problem-statement" class="heading-anchor">#</a>
</h1>
<p>At a high level, we want to derive an algorithm for learning the parameters of an HMM given some data. In order to do that, let&rsquo;s digress briefly to look at what it means to use an HMM as a generative model.</p>
<h2 id="hmms-as-generative-model">
HMMs as Generative Model
<a href="#hmms-as-generative-model" class="heading-anchor">#</a>
</h2>
<p>As you might guess from the notation section, we can think of an HMM as a model that generates sequences of emissions given some sequence of hidden states. Concretely, we can generate a sequence from an HMM by repeatedly alternating between sampling from the transition distribution to decide the next state to enter and then sampling from the emission distribution conditional on the state we entered.</p>
<p>Assuming we are given the emitted sequence \( x \) and hidden states \( \pi \) (and start in some state from \( S \)), we can factorize their joint probability as follows
\[ P(x, \pi) = \prod_{t=1}^T P(T_{\pi_t, \pi_{t+1}} E_{\pi_t, x_t} \].
While we&rsquo;re more interested in the situation where we have some data and we want to find HMM settings that make it likely, having the generative perspective on HMMs in mind is useful for understanding why what we&rsquo;re about to do can be reasonable thing to do.</p>
<h2 id="motivating-example">
Motivating Example
<a href="#motivating-example" class="heading-anchor">#</a>
</h2>
<p>The actual problem we&rsquo;re interested in, as I alluded to above, is we have some data that we want to learn a generative model of, but we don&rsquo;t know the distribution that produced it. A simple example of an application for which this might be useful (that we covered in the class in which I learned about this) is the following genetics-related one. Say you have some gene sequences, i.e. a sequence of characters drawn from {ACTG}, and you believe some of them came from a region in which CGs are very common and others came from a region in which sequences are distributed randomly. We can frame this as the problem of learning the transition and emission probabilities of a two state HMM with states &ldquo;region 1&rdquo; and &ldquo;region 2&rdquo; and emission options &ldquo;A&rdquo;, &ldquo;C&rdquo;, &ldquo;T&rdquo;, &ldquo;G&rdquo;.</p>
<p>_Note that all of what follows assumes that we have some HMM structure in mind. Coming up with that structure is outside the scope of this post.*</p>
<h2 id="formalizing-the-problem">
Formalizing the Problem
<a href="#formalizing-the-problem" class="heading-anchor">#</a>
</h2>
<p>The easiest way to think about this problem is through the lens of probabilistic modeling. So let&rsquo;s start by framing our problem in terms of probabilistic inference. We&rsquo;ve been given dataset \( X \), which we think of as having been generated by our model via the process described above. So, our problem is one of finding parameters \( \theta = \{E, T\} \) which maximize the <em>likelihood</em> of our data,
\[ \mathcal{L}(\theta \mid X) = P(X \mid \theta). \]</p>
<p>Looking at it this way, we can think about our hidden states as <em>latent variables</em>. If we know their values, we&rsquo;d be able to compute the above likelihood efficiently, but we don&rsquo;t.</p>
<p>Before I go on, I should note that there&rsquo;s a Bayesian version of this where we have priors on \( E \) and \( T \) but I&rsquo;m not going to talk about it here.</p>
<h1 id="derivation">
Derivation
<a href="#derivation" class="heading-anchor">#</a>
</h1>
<p>We have our goal, find the parameters that maximize the likelihood of our data. Now, we just have to solve it. Eezy peezy lemon squeezy.</p>
<p>I&rsquo;m going to give a spoiler and tell you now that there&rsquo;s no closed form solution for the parameters that maximize the likelihood of our data. So, at a high level, you can guess that this derivation will actually involve coming up with some way to iteratively update our estimates.</p>
<h2 id="naive-approach">
Naive Approach
<a href="#naive-approach" class="heading-anchor">#</a>
</h2>
<p>Even though I spoiled the fact that there&rsquo;s no closed form solution for this problem, we should still try Maximum Likelihood Estimation to see if we can find one. Let&rsquo;s try to maximize our (log) likelihood. By algebra and basic rules of \( \log \) we have,
\[
\begin{align}
\mathop{\mathrm{arg\ max}}_\theta P(X \mid \theta) &amp;= \mathop{\mathrm{arg\ max}}_\theta \log P(X \mid \theta) \\\
&amp;= \mathop{\mathrm{arg\ max}}_\theta \log \prod_{i=1}^m P(X_i \mid \theta) \\\
&amp;= \mathop{\mathrm{arg\ max}}_\theta \sum_{i=1}^m \log P(X_i \mid \theta).
\end{align}
\]</p>
<p>And&hellip; why&rsquo;d I stop?</p>
<p>Say we try to compute \( \log P(x \mid \theta) \) for some \( x \in X \). The clearest way to do this would be by summing over all possible hidden state sequences. If we do this, we get
\[ \log P(x \mid \theta) = \log \sum_{\pi} P(x, \pi \mid \theta). \]
Unfortunately, for a single emission sequence, there&rsquo;s \( K^T \) possible state sequences, so computing all these joint probabilities won&rsquo;t be computationally tractable in practice. Another thing to note here that is discussed in Murphy but I haven&rsquo;t verified myself is that</p>
<p>But, we did make some good progress by figuring out that the obstacle we need to overcome is: find a tractable way to at least estimate ( \log P(x \mid \theta) ) without iterating over all possible hidden state sequences. This also helps us understand better why we shouldn&rsquo;t expect to find a computationally tractable closed-form solution for this problem.</p>
<h2 id="savvy-approach">
Savvy Approach
<a href="#savvy-approach" class="heading-anchor">#</a>
</h2>
<h3 id="commentary">
Commentary
<a href="#commentary" class="heading-anchor">#</a>
</h3>
<p>This problem we&rsquo;re encountering seems to be fairly common in probabilistic machine learning. We want to get an estimate of some values and we have a formula for it, but computing that formula in practice requires summing over all possible values of some random variable which can take on <strong>a lot</strong> of values or is just hard to optimize. So instead, we find a proxy for the thing we actually want that&rsquo;s faster to compute and/or easier to optimize, but relates to our actual target in such a way that optimizing the proxy will optimize the target. While we&rsquo;re talking about Expectation Maximization in this post, Variational Inference involves a lot of similar ideas.</p>
<p>The approach we take here will be of that flavor. We&rsquo;ll derive a formula that allows us to use an existing estimate of our parameters to find a new estimate that&rsquo;s guaranteed to increase the likelihood of our data relative to the current one. This is a form of expectation maximization, so named because we&rsquo;re going to find a formula for the expectation of the likelihood with respect to a computable proxy and then maximize it.</p>
<h3 id="deriving-the-proxy">
Deriving the Proxy
<a href="#deriving-the-proxy" class="heading-anchor">#</a>
</h3>
<p>Recall that we want to derive a proxy for our \( \log \) likelihood that we can optimize directly and be confident we&rsquo;re also pushing the value of our true likelihood in the right direction. We&rsquo;re going to accomplish that by deriving a proxy that we can guarantee is \( \leq \) to our true likelihood, and we&rsquo;d also like it to have clear conditions for when equality holds.</p>
<p>I found this part really confusing when I first saw it, but bear with me and I&rsquo;ll try to make it as motivated as possible. Looking at our likelihood equation for the joint likelihood of our data and latent variables (with the matrix of all latent variables denoted as \( Z \)),
\[
\begin{equation} \label{eq:1}
\log P(X, Z \mid \theta),
\end{equation}
\]
we see that for any <strong>distribution</strong> function \( q(Z) \),
\[
\begin{equation} \label{eq:2}
\log P(X, Z \mid \theta) = q(Z) \frac{\log P(X, Z \mid \theta)}{q(Z)},
\end{equation}
\]</p>
</section>
  <section><footer class="page-footer">
<hr />

<div class="previous-post" style="display:inline-block;">
  
  <a class="link-reverse" href="http://localhost:57852/post/2019-08-13-against-athletic-recruiting/?ref=footer">« Against Athletic Recruiting</a>
  
</div>

<div class="next-post", style="display:inline-block;float:right;">
  
  <a class="link-reverse" href="http://localhost:57852/learning/2019-11-02-ivs-mendelian-randomization/?ref=footer">Paper Review - IVs and Mendelian Randomization »</a>
  
</div>

<ul class="page-footer-menu">
  
  
  <li><a href="https://twitter.com/an1lam">Twitter</a></li>
  
  
  

  
  <li><a href="https://github.com/an1lam">GitHub</a></li>
  

  

  

  

  

  

  

  

  

  

  
  <li><a href="https://scholar.google.com/citations?user=Q6_3PJEAAAAJ">Google Scholar</a></li>
  
  
  
    <li><a href="https://github.com/an1lam"><i class='fa fa-github fa-2x'></i>  </a></li>
  
    <li><a href="https://twitter.com/an1lam"><i class='fa fa-twitter fa-2x'></i>  </a></li>
  
    <li><a href="mailto:stephenmalina@gmail.com"><i class='fa fa-envelope fa-2x'></i>  </a></li>
  
    <li><a href="https://stackoverflow.com/users/1631855/an1lam"><i class='fa fa-stack-overflow fa-2x'></i>  </a></li>
  
</ul>


<p>
  Powered by <a href="https://gohugo.io">Hugo</a> and the
  <a href="https://github.com/loikein/hugo-tufte">Tufte theme</a>.
</p>




</footer>
</section>
  <section><nav class="menu">
    <ul>
    
        <li><a href="/">Home</a></li>
    
        <li><a href="/about">About</a></li>
    
        <li><a href="/post">Post</a></li>
    
        <li><a href="/bets">Bets</a></li>
    
        <li><a href="/fiction">Fiction</a></li>
    
        <li><a href="/greatest-hits">Greatest Hits</a></li>
    
        <li><a href="/tags">Tags</a></li>
    
    </ul>
</nav>
</section>
</article>







  <script>(function(){var e,t,n,s=document.getElementsByTagName("code");for(n=0;n<s.length;){if(t=s[n],t.parentNode.tagName!=="PRE"&&t.childElementCount===0&&!t.classList.contains("nolatex")&&(e=t.textContent,/^\$[^$]/.test(e)&&/[^$]\$$/.test(e)&&(e=e.replace(/^\$/,"\\(").replace(/\$$/,"\\)"),t.textContent=e),/^\\\((.|\s)+\\\)$/.test(e)||/^\\\[(.|\s)+\\\]$/.test(e)||/^\$(.|\s)+\$$/.test(e)||/^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(e))){t.outerHTML=t.innerHTML;continue}n++}})()</script>


<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css" crossorigin="anonymous">
<script defer src="//cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js" crossorigin="anonymous"></script>
<script defer src="//cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js" crossorigin="anonymous"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            
            
            
            
            
            
            trust: (context) => ['\\htmlId', '\\href'].includes(context.command),
            macros: {
              "\\eqref": "\\href{###1}{(\\text{#1})}",
              "\\ref": "\\href{###1}{\\text{#1}}",
              "\\label": "\\htmlId{#1}{}"
            }
        });
    });
</script>



</body>

</html>
