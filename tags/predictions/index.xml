<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Predictions on Stephen Malina</title>
    <link>https://stephenmalina.com/tags/predictions/</link>
    <description>Recent content in Predictions on Stephen Malina</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 07 Aug 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://stephenmalina.com/tags/predictions/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Reviewing my GPT-5 predictions</title>
      <link>https://stephenmalina.com/post/2025-08-07-reviewing-my-gpt5-predictions/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0000</pubDate>
      <guid>https://stephenmalina.com/post/2025-08-07-reviewing-my-gpt5-predictions/</guid>
      <description>&lt;p&gt;Earlier today (on August 7th), I realized that I was about to miss a golden opportunity to quickly test how calibrated I was about AI progress by predicting some GPT-5 benchmark scores. Upon realizing this, I dashed off some quick predictions based on a combination of then-current top benchmark scores and my intuition about how big a jump GPT-5 would be over o3, Grok 4, Claude Opus 4, and Gemini 2.5 Pro. I suspect many people just want the editorializing, so I put the full set of predictions at the end of the post after the analysis. In one sentence, I’d describe their underlying sentiment as “progress continues apace along the trendline but without a discontinuous jump.”&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Omens: 2&#43; Years Later</title>
      <link>https://stephenmalina.com/post/2025-05-31-reflecting-on-ai-omens/</link>
      <pubDate>Sat, 31 May 2025 00:00:00 +0000</pubDate>
      <guid>https://stephenmalina.com/post/2025-05-31-reflecting-on-ai-omens/</guid>
      <description>&lt;p&gt;In September 2022, I wrote a &lt;a href=&#34;https://stephenmalina.com/post/2022-09-17-ai-omens/&#34;&gt;post&lt;/a&gt; describing a set of &amp;ldquo;omens&amp;rdquo; that, if observed, would indicate faster-than-expected AI progress. I framed many of these in the context of 0-5 years, but obviously AI moves too fast to wait until 2027 to review these. Consider this post an arbitrarily timed intermediate check in triggered by my sense that many of my omens had come to pass.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;The rest of this post assumes you&amp;rsquo;ve skimmed the omens post, so if you haven&amp;rsquo;t already, I recommend doing that now.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>GPT4 Predictions</title>
      <link>https://stephenmalina.com/post/2022-11-16-gpt4-predictions/</link>
      <pubDate>Wed, 16 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://stephenmalina.com/post/2022-11-16-gpt4-predictions/</guid>
      <description>&lt;p&gt;As a way to keep myself honest, I&amp;rsquo;m going to be recording GPT4 predictions here and archiving versions of the post so I can&amp;rsquo;t go back and change it without people knowing. Not that I would do this anyway, but it&amp;rsquo;s been a tough week for &amp;ldquo;trust me, I&amp;rsquo;m telling the truth&amp;rdquo; so I&amp;rsquo;m doing this in case readers want the receipts.&lt;/p&gt;&#xA;&lt;h2 id=&#34;i-predict-gpt4-wont-be-able-to&#34;&gt;&#xA;I predict GPT4 won&amp;rsquo;t be able to&amp;hellip;&#xA;&lt;a href=&#34;#i-predict-gpt4-wont-be-able-to&#34; class=&#34;heading-anchor&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Write a blog post about gene therapy that I consider to be of equivalent quality to my own&lt;/li&gt;&#xA;&lt;li&gt;Write a scientific paper about machine learning. As many prompts as possible allowed but the entire paper&amp;rsquo;s text needs to be written by the model with no editing.&lt;/li&gt;&#xA;&lt;li&gt;Solve three problems from a recent programming competition on Leetcode (&lt;a href=&#34;https://manifold.markets/StephenMalina/out-of-three-randomly-chosen-leetco-49075ae75696&#34;&gt;Manifold market&lt;/a&gt;)&lt;/li&gt;&#xA;&lt;li&gt;Describe the analogy between different framings of machine learning concepts&#xA;&lt;ul&gt;&#xA;&lt;li&gt;E.g. describe the Bayesian perspective on training deep learning models&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Correctly solve 10 randomly chosen problems from &lt;em&gt;Linear Algebra Done Right&lt;/em&gt; without chain-of-thought prompting or few-shot examples.&lt;/li&gt;&#xA;&lt;li&gt;Describe a coherent design for a machine learning model training platform and answer my questions about it&lt;/li&gt;&#xA;&lt;li&gt;Find the solution to an unsolved as of its deployment scientific problem.&lt;/li&gt;&#xA;&lt;li&gt;Play Nethack better than &lt;a href=&#34;https://www.reddit.com/r/reinforcementlearning/comments/rtp5ts/nethack_2021_neurips_challenge_winning_agent/&#34;&gt;the winner of 2021&amp;rsquo;s NeurIPS Nethack challenge&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;i-predict-gpt4-will-be-able-to&#34;&gt;&#xA;I predict GPT4 will be able to&amp;hellip;&#xA;&lt;a href=&#34;#i-predict-gpt4-will-be-able-to&#34; class=&#34;heading-anchor&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Solve &amp;gt;18/20 multiplication problems I come up with that have between 3-6 digits in the multiplicands.&lt;/li&gt;&#xA;&lt;li&gt;Write internet marketing-style blog posts about relatively popular topics&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Ex: &amp;ldquo;You&amp;rsquo;re marketing a new product that tracks my keyboard presses to determine where I&amp;rsquo;m spending my time. The following is copy for a press release about it.&amp;rdquo;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;appendix&#34;&gt;&#xA;Appendix&#xA;&lt;a href=&#34;#appendix&#34; class=&#34;heading-anchor&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;gpt3s-current-attempts-at-some-of-these-tasks&#34;&gt;&#xA;GPT3&amp;rsquo;s current attempts at some of these tasks&#xA;&lt;a href=&#34;#gpt3s-current-attempts-at-some-of-these-tasks&#34; class=&#34;heading-anchor&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;em&gt;Requires GPT3 API access.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Omens: Signs of AI acceleration</title>
      <link>https://stephenmalina.com/post/2022-09-17-ai-omens/</link>
      <pubDate>Sat, 17 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://stephenmalina.com/post/2022-09-17-ai-omens/</guid>
      <description>&lt;p&gt;A friend recently asked me what my &amp;ldquo;&lt;a href=&#34;https://www.cold-takes.com/where-ai-forecasting-stands-today/&#34;&gt;AI timelines&lt;/a&gt;&amp;rdquo; were. Especially with recent progress in &lt;a href=&#34;https://openai.com/dall-e-2/&#34;&gt;image&lt;/a&gt; &lt;a href=&#34;https://parti.research.google/&#34;&gt;generation&lt;/a&gt;, &lt;a href=&#34;https://openai.com/api/&#34;&gt;language&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2203.15556&#34;&gt;modeling&lt;/a&gt;, &lt;a href=&#34;https://openai.com/blog/openai-codex/&#34;&gt;code generation&lt;/a&gt;, &lt;a href=&#34;https://sites.research.google/palm-saycan&#34;&gt;robotics&lt;/a&gt;, &lt;a href=&#34;https://www.nature.com/articles/s41586-021-03819-2&#34;&gt;protein folding&lt;/a&gt;, and &lt;a href=&#34;https://www.adept.ai/act&#34;&gt;other&lt;/a&gt; areas, this has become an increasingly popular question amongst those who are paying attention.&lt;/p&gt;&#xA;&lt;p&gt;However, I find trying to answer this question pretty frustrating. There already exist &lt;a href=&#34;https://www.alignmentforum.org/posts/KrJfoZzpSDpnrv9va/draft-report-on-ai-timelines&#34;&gt;long, thorough reports&lt;/a&gt; (&lt;a href=&#34;https://www.openphilanthropy.org/research/report-on-whether-ai-could-drive-explosive-economic-growth/&#34;&gt;another&lt;/a&gt;) which build quantitative models and carefully define terms to make sure there&amp;rsquo;s as little ambiguity as possible. These reports then get carefully debated (&lt;a href=&#34;https://www.lesswrong.com/posts/ax695frGJEzGxFBK4/biology-inspired-agi-timelines-the-trick-that-never-works&#34;&gt;here&lt;/a&gt;, &lt;a href=&#34;https://www.alignmentforum.org/posts/qnjDGitKxYaesbsem/a-comment-on-ajeya-cotra-s-draft-report-on-ai-timelines#My_core_contention&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://nostalgebraist.tumblr.com/post/693718279721730048/on-bio-anchors&#34;&gt;here&lt;/a&gt;). I genuinely admire the authors of these reports and critiques for putting in so much time and energy into answering this question, but as someone who doesn&amp;rsquo;t work directly on advancing &amp;ldquo;pure&amp;rdquo; AI, I find it emotionally difficult to get myself to invest the time required to develop an opinion on them and then have them inform my own mythical personal timelines estimate. I recognize all that shouldn&amp;rsquo;t stop me because it&amp;rsquo;s important, but I suspect some of my aversion also comes from feeling like it&amp;rsquo;s also overrated as an activity, especially by certain sects of the internet.&lt;/p&gt;</description>
    </item>
    <item>
      <title>2050 Predictions</title>
      <link>https://stephenmalina.com/post/2022-01-01-2050-predictions/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://stephenmalina.com/post/2022-01-01-2050-predictions/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;&#xA;Introduction&#xA;&lt;a href=&#34;#introduction&#34; class=&#34;heading-anchor&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Along with a few internet blogger friends, inspired by Erik Hoel&amp;rsquo;s &lt;a href=&#34;https://erikhoel.substack.com/p/futurists-have-their-heads-in-the&#34;&gt;post&lt;/a&gt; (parts of which I disagree with, including the headline), I&amp;rsquo;ve decided to make predictions for 2050. The rest of this post discusses some meta aspects of making these predictions and then lists out the predictions. In case you&amp;rsquo;re waiting for my (hopefully) less speculative 2022 annual predictions, fear not! Those will be coming in the next few weeks.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Scoring my 2021 Predictions</title>
      <link>https://stephenmalina.com/post/2021-12-31-scoring-my-2021-predictions/</link>
      <pubDate>Fri, 31 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://stephenmalina.com/post/2021-12-31-scoring-my-2021-predictions/</guid>
      <description>&lt;p&gt;At the beginning of last year, I &lt;a href=&#34;https://stephenmalina.com/post/2021-01-09-2021-predictions/&#34;&gt;made predictions&lt;/a&gt; for the year. Now it&amp;rsquo;s time to score them (before I make my 2022 predictions).&lt;/p&gt;&#xA;&lt;h2 id=&#34;data--code&#34;&gt;&#xA;Data &amp;amp; code&#xA;&lt;a href=&#34;#data--code&#34; class=&#34;heading-anchor&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://docs.google.com/spreadsheets/d/1YQZfLKDxxsfawwuvWLWkeoxoj9jRfUCOCQbshtE0EwM/edit?usp=sharing&#34;&gt;Here&lt;/a&gt; is a spreadsheet containing my scored predictions. If you want to see my full analysis, you can look at my &lt;a href=&#34;https://github.com/an1lam/predictions/blob/main/notebooks/2021%20Predictions%20Scoring.ipynb&#34;&gt;Jupyter notebook&lt;/a&gt; which contains Brier score calculations plus plotting.&lt;/p&gt;&#xA;&lt;h2 id=&#34;high-level-analysis&#34;&gt;&#xA;High level analysis&#xA;&lt;a href=&#34;#high-level-analysis&#34; class=&#34;heading-anchor&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;The key metrics I looked at were my overall and by category &lt;a href=&#34;https://en.wikipedia.org/wiki/Brier_score&#34;&gt;Brier scores&lt;/a&gt; plus calibration. My overall Brier score was .18.&#xA;&lt;label for=&#34;sidenote-1&#34; class=&#34;margin-toggle sidenote-number&#34;&gt;(1)&lt;/label&gt;&#xA;&lt;input type=&#34;checkbox&#34; id=&#34;sidenote-1&#34; class=&#34;margin-toggle&#34;/&gt;&#xA;&lt;span class=&#34;sidenote&#34;&gt;&#xA;&lt;span class=&#34;sidenote-number&#34;&gt;(1)&lt;/span&gt;As a refresher, the Brier score is the mean squared error of a set of predictions vs. the true outcomes. So, for example, if I predict something will happen with probability .2 and something else will happen with probability .4 and then both happen, my Brier score for this pair of events is $ ((1-.2)^2 + (1-.4)^2)/2 = .5$. This means that lower Brier scores are better, with the best possible Brier score being 0 and the worst 1. The Brier score is a &lt;a href=&#34;https://en.wikipedia.org/wiki/Scoring_rule#StrictlyProperScoringRules&#34;&gt;strictly proper scoring rule&lt;/a&gt;, which means that it will always be maximized by the true probabilities (assuming they were known) for a set of events. Note that despite this, Brier scores are &lt;a href=&#34;https://en.wikipedia.org/wiki/Brier_score#Shortcomings&#34;&gt;not ideal&lt;/a&gt; for very rare events. The intuition for why this can be true despite them being strictly proper scoring rules boils down to the strictly proper condition only requiring that the score decrease as the result of any one prediction diverging from the probability of the event rather than dictating by &lt;em&gt;how much&lt;/em&gt;.&#xA;&lt;/span&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>2021 Predictions</title>
      <link>https://stephenmalina.com/post/2021-01-09-2021-predictions/</link>
      <pubDate>Sat, 09 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://stephenmalina.com/post/2021-01-09-2021-predictions/</guid>
      <description>&lt;p&gt;For the past two years, my friends have had a tradition of making predictions and scoring them at the end of the year. This year, I decided why not just post my predictions on my blog and score them publicly (with a few redacted)? This will hopefully incentivize me to be more thoughtful about them and also will help direct my endless desire for internet acclaim towards something that has a positive side effect.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
